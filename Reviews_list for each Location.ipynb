{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import RegexpTokenizer as regextoken\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, bigrams, trigrams,ngrams\n",
    "from nltk import WordNetLemmatizer\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# import gensim\n",
    "# from gensim.models.keyedvectors import KeyedVectors\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Embedding, Conv1D, MaxPooling1D, Dropout, LSTM, GRU\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "zomato = pd.read_csv(\"zomato.csv\", na_values = [\"-\", \"\"])\n",
    "# Making a copy of the data to work on\n",
    "data = zomato.copy()\n",
    "data.drop(['url','address','menu_item','phone','location'],axis=1,inplace=True)\n",
    "data.rename(columns={'listed_in(city)':'location'}, inplace=True)\n",
    "data=data[data['rate'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ch=data[data['name'].str.contains('urch Street Social')].head(1).copy()\n",
    "# ch=ch.drop('listed_in(type)',axis=1)\n",
    "# ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam=data[['reviews_list','location']].groupby(['location'],as_index=False).agg(lambda x :' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heybi={}\n",
    "for i in range(0,30):\n",
    "    s=sam[sam.index==i]\n",
    "    s[\"reviews_list\"]= s[\"reviews_list\"].apply(lambda x: x.lower())\n",
    "    tokenizer = regextoken(\"[a-zA-Z]+\") \n",
    "    review_tokens =s[\"reviews_list\"].apply(tokenizer.tokenize)\n",
    "    stop = stopwords.words(\"english\")\n",
    "    stop.extend([\"rated\", \"n\", \"nan\", \"x\"])\n",
    "    review_tokens = review_tokens.apply(lambda x: [token for token in x if token not in stop])\n",
    "    all_reviews = review_tokens.astype(str).str.cat()\n",
    "    cleaned_reviews = tokenizer.tokenize(all_reviews)\n",
    "    j=s['location'].values[0]\n",
    "    heybi[j] = cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "three={}\n",
    "for i in heybi.keys():\n",
    "    trigram = lambda a: zip(a, a[1:],a[2:])\n",
    "    ap=list(trigram(heybi[i]))\n",
    "    trigramFreq = collections.Counter(ap)\n",
    "    three[i]=trigramFreq.most_common(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('must', 'visit', 'place'), 721), (('veg', 'non', 'veg'), 706), (('place', 'hangout', 'friends'), 667), (('place', 'hang', 'friends'), 596), (('north', 'indian', 'food'), 498), (('good', 'food', 'good'), 458), (('food', 'really', 'good'), 455), (('nfood', 'nambience', 'nservice'), 396), (('good', 'place', 'hangout'), 376), (('nfood', 'nservice', 'nambience'), 353)]\n"
     ]
    }
   ],
   "source": [
    "print(three['BTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('south', 'indian', 'food'), 129), (('must', 'visit', 'place'), 97), (('good', 'food', 'good'), 89), (('paneer', 'tikka', 'biriyani'), 86), (('north', 'indian', 'chinese'), 83), (('north', 'indian', 'food'), 79), (('worst', 'food', 'ever'), 70), (('paneer', 'butter', 'masala'), 68), (('delious', 'good', 'need'), 58), (('good', 'need', 'sum'), 58)]\n"
     ]
    }
   ],
   "source": [
    "print(three['Banashankari'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('must', 'visit', 'place'), 425), (('peri', 'peri', 'chicken'), 390), (('veg', 'non', 'veg'), 382), (('place', 'hangout', 'friends'), 360), (('food', 'really', 'good'), 319), (('one', 'best', 'places'), 318), (('nfood', 'nambience', 'nservice'), 272), (('mg', 'road', 'metro'), 270), (('overall', 'good', 'experience'), 238), (('road', 'metro', 'station'), 233)]\n"
     ]
    }
   ],
   "source": [
    "print(three['Church Street'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('f', 'f', 'f'), 2353), (('f', 'c', 'f'), 1928), (('c', 'f', 'f'), 1377), (('f', 'f', 'c'), 1355), (('must', 'visit', 'place'), 752), (('veg', 'non', 'veg'), 606), (('peri', 'peri', 'chicken'), 560), (('one', 'best', 'places'), 455), (('place', 'hangout', 'friends'), 445), (('nfood', 'nambience', 'nservice'), 415)]\n"
     ]
    }
   ],
   "source": [
    "print(three['MG Road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('f', 'f', 'f'), 1798), (('f', 'c', 'f'), 1158), (('c', 'f', 'f'), 778), (('f', 'f', 'c'), 740), (('must', 'visit', 'place'), 623), (('veg', 'non', 'veg'), 482), (('one', 'best', 'places'), 421), (('xa', 'xa', 'xa'), 377), (('peri', 'peri', 'chicken'), 376), (('place', 'hangout', 'friends'), 365)]\n"
     ]
    }
   ],
   "source": [
    "print(three['Residency Road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('f', 'f', 'f'), 1850), (('f', 'c', 'f'), 585), (('xa', 'xa', 'xa'), 453), (('north', 'indian', 'food'), 412), (('must', 'visit', 'place'), 400), (('c', 'f', 'f'), 374), (('veg', 'non', 'veg'), 349), (('f', 'e', 'f'), 306), (('e', 'f', 'e'), 278), (('f', 'f', 'c'), 269)]\n"
     ]
    }
   ],
   "source": [
    "print(three['Old Airport Road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting=data[['name','location','votes']].groupby(['location']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt=data[['name','location','rate','votes','reviews_list']][(data['location']=='Banashankari') &(data['rate']!='NEW')].sort_values(by='rate').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt['rate']=rt['rate'].str[:3]\n",
    "# rt['rate']=rt['rate'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['rate']=data['rate'].str[:3]\n",
    "# rt['rate']=rt['rate'].astype(float)\n",
    "# rt[(rt['rate']>=4.0)& (rt['votes']<200)].sort_values(by=['rate','votes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad=rt[rt['name']=='Udupi Ruchi Grand'].head(1).iloc[:,:-1]\n",
    "# bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [('Rated 1.0', 'RATED\\n Ordered on zomato delivery for curiosity... Food was good but the quantity was as good as nothing... The 2 portions fo bhel puri received was not even the half you normally get from other places... Half of the silver container was pressed from bottom to appear the contents to be full... Pav bhaji was received with 3/4 of the plastic container without chopped onions and lemon.... Waste of money...')\n",
    "\n",
    "## 'Rated 3.0', 'RATED\\n The newly opened one at a prime location offers south Indian and north Indian cuisines.. I had ordered paneer tikka masala on a rainy day, so cheers to the service .. I received the order on time. The food dint taste great but not bad to be tried too , a good one flavoursome gravy..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting.sort_values(by='votes',ascending=False).tail()\n",
    "#28th lowest no.of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptr=data[['name','location','rate','votes','approx_cost(for two people)']][(data['location']=='Old Airport Road') &(data['rate']!='NEW')].sort_values(by='rate').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptr['rate']=ptr['rate'].str[:3]\n",
    "# ptr['rate']=ptr['rate'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptr['approx_cost(for two people)']=ptr['approx_cost(for two people)'].str.replace(',','')\n",
    "\n",
    "# ptr['approx_cost(for two people)']=ptr['approx_cost(for two people)'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptr=ptr[ptr['approx_cost(for two people)'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptr[(ptr['rate']>4) & (ptr['approx_cost(for two people)']>1000)].sort_values(by='approx_cost(for two people)',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptr[(ptr['rate']>4) & (ptr['approx_cost(for two people)']>1000)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
