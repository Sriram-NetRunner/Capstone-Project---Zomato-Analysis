{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import RegexpTokenizer as regextoken\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, bigrams, trigrams,ngrams\n",
    "from nltk import WordNetLemmatizer\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# import gensim\n",
    "# from gensim.models.keyedvectors import KeyedVectors\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Embedding, Conv1D, MaxPooling1D, Dropout, LSTM, GRU\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import classification_report\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "zomato = pd.read_csv(\"zomato.csv\", na_values = [\"-\", \"\"])\n",
    "# Making a copy of the data to work on\n",
    "data = zomato.copy()\n",
    "data.drop(['url','address','menu_item','phone','location'],axis=1,inplace=True)\n",
    "data.rename(columns={'listed_in(city)':'location'}, inplace=True)\n",
    "data=data[data['rate'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cuisines\"] = data[\"cuisines\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam=data[['cuisines','location']].groupby(['location'],as_index=False).agg(lambda x:' '.join(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair={}\n",
    "for i in range(0,30):\n",
    "    s=sam[sam.index==i]\n",
    "    s[\"cuisines\"]= s[\"cuisines\"].apply(lambda x: x.lower())\n",
    "    tokenizer = regextoken(\"[a-zA-Z]+\") \n",
    "    cuisine_tokens = s[\"cuisines\"].apply(tokenizer.tokenize)\n",
    "    all_cuisines = cuisine_tokens.astype(str).str.cat()\n",
    "    cleaned_cuisines = tokenizer.tokenize(all_cuisines)\n",
    "    j=s['location'].values[0]\n",
    "    pair[j] = cleaned_cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pair.keys():\n",
    "    trigram = lambda a: zip(a, a[1:],a[2:])\n",
    "    ap=list(trigram(pair[i]))\n",
    "    trigramFreq = collections.Counter(ap)\n",
    "    tree[i]=trigramFreq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "too={}\n",
    "for i in pair.keys():    \n",
    "    bigram = lambda a: zip(a, a[1:])\n",
    "    apw=list(bigram(pair[i]))\n",
    "    bigramFreq = collections.Counter(apw)\n",
    "    too[i]=bigramFreq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BTM', 'Banashankari', 'Bannerghatta Road', 'Basavanagudi', 'Bellandur', 'Brigade Road', 'Brookefield', 'Church Street', 'Electronic City', 'Frazer Town', 'HSR', 'Indiranagar', 'JP Nagar', 'Jayanagar', 'Kalyan Nagar', 'Kammanahalli', 'Koramangala 4th Block', 'Koramangala 5th Block', 'Koramangala 6th Block', 'Koramangala 7th Block', 'Lavelle Road', 'MG Road', 'Malleshwaram', 'Marathahalli', 'New BEL Road', 'Old Airport Road', 'Rajajinagar', 'Residency Road', 'Sarjapur Road', 'Whitefield'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('chinese', 'north'), 44),\n",
       " (('fast', 'food'), 162),\n",
       " (('food', 'south'), 35),\n",
       " (('indian', 'chinese'), 166),\n",
       " (('indian', 'fast'), 35),\n",
       " (('indian', 'north'), 99),\n",
       " (('indian', 'south'), 65),\n",
       " (('north', 'indian'), 286),\n",
       " (('south', 'indian'), 227),\n",
       " (('street', 'food'), 72)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(too['Banashankari'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
